---
title: "R Notebook"
author: "Sean Bradford"
output:
  pdf_document:
    latex_engine: xelatex
  html_notebook: default
  word_document: default
  html_document:
    df_print: paged
---

```{r}
rm(list=ls())

library(ISLR)
library(cluster)
library(factoextra)
library(Rfast)
library(analogue)
library(caret)
```

```{r}
cereal=read.csv("C:\\Users\\Sean\\OneDrive\\Desktop\\Grad School\\Machine Learning\\Module 8 - Hierarchial Clustering\\Cereals.csv")

rownames(cereal)=cereal$name

cereal=cereal[,-1]

head(cereal)
# columns 1,2,12 are categorical and need to be removed before normalization
norm_cereal=scale(cereal[,c(-1,-2,-12)])

# Removing N/A values from data
norm_cereal=as.data.frame(na.omit(norm_cereal))
```

1. Apply hierarchical clustering to the data using Euclidean distance to the normalized 
measurements. Use Agnes to compare the clustering from single linkage, complete 
linkage, average linkage, and Ward. Choose the best method.

```{r}
single=agnes(norm_cereal,method="single")
complete=agnes(norm_cereal,method="complete")
average=agnes(norm_cereal,method="average")
ward=agnes(norm_cereal,method="ward")

single$ac
complete$ac
average$ac
ward$ac
```
Ward is the best linkage method because it has the highest agglomerative coefficient.

```{r}
d=dist(norm_cereal,method="euclidean")
d_ward=hclust(d,method="ward.D")
plot(d_ward,cex=0.6,hang=-1)
```

2. How many clusters would you choose?

```{r}
# Testing for best k value

plot(d_ward,cex=0.6)
rect.hclust(d_ward,k=4,border=1:4)

plot(d_ward,cex=0.6)
rect.hclust(d_ward,k=6,border=1:6)
```

```{r}
k4=cutree(d_ward,k=4)
table(k4)

clustered.data=cbind.data.frame(norm_cereal,k4)
```

K = 4 appears to be the optimal value for clustering

3. Comment on the structure of the clusters and on their stability. 
Hint: To check stability, partition the data and see how well clusters formed based on one part apply to the other part. 
To do this:
● Cluster partition A
● Use the cluster centroids from A to assign each record in partition B (each record is assigned to the cluster with the closest centroid).
● Assess how consistent the cluster assignments are compared to the assignments based on all the data.

```{r}
# Cluster partition A
nrow(norm_cereal)

# Partitioning 80/20
74*0.8

train=norm_cereal[1:60,]
test=norm_cereal[61:74,]
```

```{r}
# Use cluster centroids from A to assign each record in partition B
d_train=dist(train,method="euclidean")
d_ward_train=hclust(d_train,method="ward.D")

plot(d_ward_train,cex=0.6,hang=-1)
rect.hclust(d_ward_train,k=4,border=1:4)

k4.train=cutree(d_ward_train,k=4)
table(k4.train)

train2=cbind.data.frame(train,k4.train)
```

```{r}

c.1=colMeans(train2[train2$k4.train == "1",])
c.2=colMeans(train2[train2$k4.train=="2",])
c.3=colMeans(train2[train2$k4.train=="3",])
c.4=colMeans(train2[train2$k4.train=="4",])

centroid=rbind(c.1,c.2,c.3,c.4)
test.data.centroid=rowMins(distance(test,centroid[,-13]))
partition.centoid=c(train2$k4.train,test.data.centroid)
clustered.data=cbind(clustered.data,partition.centoid)
```

```{r}
# Assess how consistent the cluster assignments are compared to the assignments based on all the data.
table(clustered.data$k4==clustered.data$partition.centoid)
table(clustered.data$k4[61:74]==clustered.data$partition.centoid[61:74])
```

```{r}
(57/74)*100
(12/14)*100
```
Cluster assignments based on test data are 85.71% consistent, and the cluster assignments based on all data are 77.03% consistent.

4. The elementary public schools would like to choose a set of cereals to include in their daily cafeterias. Every day a different cereal is offered, but all cereals should support a healthy diet. For this goal, you are requested to find a cluster of “healthy cereals.” Should the data be normalized? If not, how should they be used in the cluster analysis?


```{r}
# Calculate all centroids

ctroid1=colMeans(clustered.data[clustered.data$k4 == "1",])
ctroid2=colMeans(clustered.data[clustered.data$k4 == "2",])
ctroid3=colMeans(clustered.data[clustered.data$k4 == "3",])
ctroid4=colMeans(clustered.data[clustered.data$k4 == "4",])
ctroid.bind=rbind(ctroid1, ctroid2, ctroid3, ctroid4)

```

```{r}
# View avg nutrient values across clusters

head(ctroid.bind)

# Create heatmap to further compare cluster values

row.names(norm_cereal)=paste(k4,": ",row.names(norm_cereal),sep="")

heatmap(as.matrix(norm_cereal),Colv=NA,hclustfun=hclust,col=rev(paste("gray",1:99,sep="")))

```

The heatmap and the table "ctroid.bind" indicate that cluster 1 would be the best choice for elementary public schools. Compared to the other clusters, cluster 1 has the highest rating & fiber, second-highest protein & potassium, and the lowest calories, fat, sodium and sugar. These factors make it the healthiest choice.

The 12 cereals shown below makeup cluster 1 and would become part of the school's breakfast offering.

```{r}
clustered.data[clustered.data$k4 == '1',]
```

